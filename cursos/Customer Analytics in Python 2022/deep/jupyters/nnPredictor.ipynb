{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediciendo la compra de audiolibros\n",
    "\n",
    "En este ejemplo, lo que haremos es utilizar una red neuronal para predecir si una persona comprará o no un audiolibro. Para esto, usaremos un set de datos que contiene información de diferentes clientes, entre esta info podemos encontrar, la cantidad de veces que compro, la cantidad de veces que accedió al sitio, si dejo o no dejo una reseña, qué puntaje colocó en la reseña, entre otros.\n",
    "\n",
    "Utilizaremos [Tensorflow](https://www.tensorflow.org/?gclid=Cj0KCQiAwJWdBhCYARIsAJc4idBKBFxY8qIb2YFIXTld4WhSSr7yb-b-0EUxf2CCWwKaXOUG44Wpt6IaAueKEALw_wcB) para crear un modelo de red neuronal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.730e+02, 2.160e+03, 2.160e+03, 1.013e+01, 1.013e+01, 0.000e+00,\n",
       "       8.910e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = np.loadtxt('datasets/audiobooks_data.csv', delimiter=\",\")\n",
    "raw_data[0,:].round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesando datos\n",
    "\n",
    "Antes que nada, vamos a preprocesar los datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe\n",
    "\n",
    "Crearemos un dataframe con los datos cargados sólo para hacer un rápido análisis. Sin embargo, para entrenar y evaluar la red neuronal solo usaremos *raw_data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Book length (mins)_overall</th>\n",
       "      <th>Book length (mins)_avg</th>\n",
       "      <th>Price_overall</th>\n",
       "      <th>Price_avg</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review 10/10</th>\n",
       "      <th>Completion</th>\n",
       "      <th>Minutes Listened</th>\n",
       "      <th>Support Requests</th>\n",
       "      <th>Last visited minus Purchase date</th>\n",
       "      <th>Targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>873.0</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>10.13</td>\n",
       "      <td>10.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>611.0</td>\n",
       "      <td>1404.0</td>\n",
       "      <td>2808.0</td>\n",
       "      <td>6.66</td>\n",
       "      <td>13.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>705.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>10.13</td>\n",
       "      <td>10.13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>391.0</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>15.31</td>\n",
       "      <td>15.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>819.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>7.11</td>\n",
       "      <td>21.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Book length (mins)_overall  Book length (mins)_avg  Price_overall  \\\n",
       "0  873.0                      2160.0                  2160.0          10.13   \n",
       "1  611.0                      1404.0                  2808.0           6.66   \n",
       "2  705.0                       324.0                   324.0          10.13   \n",
       "3  391.0                      1620.0                  1620.0          15.31   \n",
       "4  819.0                       432.0                  1296.0           7.11   \n",
       "\n",
       "   Price_avg  Review  Review 10/10  Completion  Minutes Listened  \\\n",
       "0      10.13     0.0          8.91         0.0               0.0   \n",
       "1      13.33     1.0          6.50         0.0               0.0   \n",
       "2      10.13     1.0          9.00         0.0               0.0   \n",
       "3      15.31     0.0          9.00         0.0               0.0   \n",
       "4      21.33     1.0          9.00         0.0               0.0   \n",
       "\n",
       "   Support Requests  Last visited minus Purchase date  Targets  \n",
       "0               0.0                               0.0      1.0  \n",
       "1               0.0                             182.0      1.0  \n",
       "2               1.0                             334.0      1.0  \n",
       "3               0.0                             183.0      1.0  \n",
       "4               0.0                               0.0      1.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnas = [\"ID\",\"Book length (mins)_overall\",\"Book length (mins)_avg\", \"Price_overall\",\n",
    "            \"Price_avg\", \"Review\", \"Review 10/10\", \"Completion\", \"Minutes Listened\",\n",
    "            \"Support Requests\", \"Last visited minus Purchase date\", \"Targets\"]\n",
    "\n",
    "raw_df = pd.DataFrame(raw_data, columns=columnas)\n",
    "# raw_df.describe().round(2).head()\n",
    "raw_df.head()\n",
    "# raw_df[raw_df[\"ID\"]==994]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book length (mins)_overall</th>\n",
       "      <th>Book length (mins)_avg</th>\n",
       "      <th>Price_overall</th>\n",
       "      <th>Price_avg</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review 10/10</th>\n",
       "      <th>Completion</th>\n",
       "      <th>Minutes Listened</th>\n",
       "      <th>Support Requests</th>\n",
       "      <th>Last visited minus Purchase date</th>\n",
       "      <th>Targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14084.000</td>\n",
       "      <td>14084.000</td>\n",
       "      <td>14084.000</td>\n",
       "      <td>14084.000</td>\n",
       "      <td>14084.000</td>\n",
       "      <td>14084.000</td>\n",
       "      <td>14084.000</td>\n",
       "      <td>14084.000</td>\n",
       "      <td>14084.000</td>\n",
       "      <td>14084.000</td>\n",
       "      <td>14084.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1591.282</td>\n",
       "      <td>1678.609</td>\n",
       "      <td>7.104</td>\n",
       "      <td>7.544</td>\n",
       "      <td>0.161</td>\n",
       "      <td>8.910</td>\n",
       "      <td>0.126</td>\n",
       "      <td>118.587</td>\n",
       "      <td>0.070</td>\n",
       "      <td>61.935</td>\n",
       "      <td>0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>504.341</td>\n",
       "      <td>654.839</td>\n",
       "      <td>4.932</td>\n",
       "      <td>5.560</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.241</td>\n",
       "      <td>268.732</td>\n",
       "      <td>0.472</td>\n",
       "      <td>88.208</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>216.000</td>\n",
       "      <td>216.000</td>\n",
       "      <td>3.860</td>\n",
       "      <td>3.860</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1188.000</td>\n",
       "      <td>1188.000</td>\n",
       "      <td>5.330</td>\n",
       "      <td>5.330</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1620.000</td>\n",
       "      <td>1620.000</td>\n",
       "      <td>5.950</td>\n",
       "      <td>6.070</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2160.000</td>\n",
       "      <td>2160.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.910</td>\n",
       "      <td>0.130</td>\n",
       "      <td>64.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>105.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2160.000</td>\n",
       "      <td>7020.000</td>\n",
       "      <td>130.940</td>\n",
       "      <td>130.940</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2116.800</td>\n",
       "      <td>30.000</td>\n",
       "      <td>464.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Book length (mins)_overall  Book length (mins)_avg  Price_overall  \\\n",
       "count                   14084.000               14084.000      14084.000   \n",
       "mean                     1591.282                1678.609          7.104   \n",
       "std                       504.341                 654.839          4.932   \n",
       "min                       216.000                 216.000          3.860   \n",
       "25%                      1188.000                1188.000          5.330   \n",
       "50%                      1620.000                1620.000          5.950   \n",
       "75%                      2160.000                2160.000          8.000   \n",
       "max                      2160.000                7020.000        130.940   \n",
       "\n",
       "       Price_avg     Review  Review 10/10  Completion  Minutes Listened  \\\n",
       "count  14084.000  14084.000     14084.000   14084.000         14084.000   \n",
       "mean       7.544      0.161         8.910       0.126           118.587   \n",
       "std        5.560      0.367         0.643       0.241           268.732   \n",
       "min        3.860      0.000         1.000       0.000             0.000   \n",
       "25%        5.330      0.000         8.910       0.000             0.000   \n",
       "50%        6.070      0.000         8.910       0.000             0.000   \n",
       "75%        8.000      0.000         8.910       0.130            64.800   \n",
       "max      130.940      1.000        10.000       1.000          2116.800   \n",
       "\n",
       "       Support Requests  Last visited minus Purchase date    Targets  \n",
       "count         14084.000                         14084.000  14084.000  \n",
       "mean              0.070                            61.935      0.159  \n",
       "std               0.472                            88.208      0.366  \n",
       "min               0.000                             0.000      0.000  \n",
       "25%               0.000                             0.000      0.000  \n",
       "50%               0.000                            11.000      0.000  \n",
       "75%               0.000                           105.000      0.000  \n",
       "max              30.000                           464.000      1.000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.iloc[:,1:].describe().round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión del dataframe\n",
    "\n",
    "Se explica brevemente qué representan algunas de las columnas.\n",
    "\n",
    "- *Book length*: representa la duración en minutos de un libro.\n",
    "- *Price overall*: precio pagado en dólares.\n",
    "- *Review*: En el caso de que *Review* sea igual a 1, el cliente dió un puntaje a su compra. Este puntaje puede ir de 1 a 10.\n",
    "- *Minutes listened*: indica la cantidad de tiempo que la persona escuchó el audiolibro.\n",
    "- *Completion*: porcentaje que indica que tanto fue escuchado el libro respecto del total (en minutos).\n",
    "- *Last visited minus Purchase date*: hace referencia a la cantidad de minutos que la persona entró al sitio desde su compra. Es esperable que mientras más grande sea este número, mayor sea la chance de que la persona compre.\n",
    "\n",
    "Antes de explicar la última columna, se debe aclarar que el set de datos que estamos usando recopila información de clientes en un lapso de tiempo de 2 años y seis meses. Los primeros dos años forman las columnas que van desde *Book length (mins)_overall* hasta *Last visited minus Purchase date*. Los otros seis meses se utilizaron para formar la columna *Targets*.\n",
    "\n",
    "- *Targets*: Esta columna contiene 0 y 1. Un cero indica que el cliente NO compro en el lapso de seis meses, y un uno indcia que sí lo hizo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completando valores cero\n",
    "\n",
    "La columna *Review 10/10* posee muchos ceros. Esto es normal, en general ninguna persona deja un review. No obstante, debemos tomar alguna medida para no dejar tantos ceros en nuestros datos. Lo que vamos a hacer es rellenar dichos valores con el promedio de la columna, el cual es $8.91$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df[raw_df[\"Review 10/10\"] == 0] = raw_df[\"Review 10/10\"].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanceando el set de datos\n",
    "\n",
    "Como siempre, debemos analizar los datos que tenemos para saber si están desbalanceados. Analicemos la columna *Targets* para ver que tan desbalanceado esta el set de datos considerando personas que sí compraron libros vs las que no han comprado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.88327179778472"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[\"Targets\"].sum()/raw_df[\"Targets\"].shape[0]*100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que tenemos sólo un 15% de personas que hayan comprado libros (también vemos esto en la tabla *describe* del dataframe). ¿Por qué es esto importante? Porque un set de datos desbalanceado provocará que nuestra red neuronal (y cualquier otro algoritmo de ML) tenga un sesgo, ya que rápidamente interpretará que la clase importante es la clase 0, es decir, la gente que no compra libros.\n",
    "\n",
    "Por lo tanto, vamos a balancear los datos. Pero antes, vamos a quedarnos con las columnas que harán las veces de *features* y la columna que hará de *target*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a balancear los datos. Lo que vamos a hacer es la técnica de *downsampling*, esto es, vamos a retirar algunas observaciones de la clase 0 (mayoritaria). Utilizaremos el método [Resample](https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html) de Scikitlearn.\n",
    "\n",
    "Info [acá](https://elitedatascience.com/imbalanced-classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2237\n",
       "1.0    2237\n",
       "Name: Targets, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clase_mayoritaria = shuffle(raw_df[raw_df[\"Targets\"] == 0], random_state = 42) #mezclamos datos\n",
    "clase_minoritaria = raw_df[raw_df[\"Targets\"] == 1] #no hace falta mezclarlos\n",
    "\n",
    "targets_uno = int(raw_df[raw_df[\"Targets\"] == 1][\"Targets\"].sum()) #cantidad de targets con valor 1\n",
    "\n",
    "# Aplicamos el downsampling\n",
    "clase_mayoritaria_downsampled = resample(clase_mayoritaria, \n",
    "                                 replace=False,    # Sin reemplazo\n",
    "                                 n_samples = targets_uno,     # Cantidad de muestras que queremos.\n",
    "                                 random_state=42) # Seteamos la semilla para tener reproducibilidad en un futuro\n",
    "\n",
    "df_balanceado = pd.concat([clase_mayoritaria_downsampled,clase_minoritaria])\n",
    "df_balanceado[\"Targets\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que ahora el set de datos está balanceado. Lo malo es que hemos perdido muestras, pero es el costo que tenemos que pagar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando variables independientes y variable dependiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Book length (mins)_overall\",\"Book length (mins)_avg\", \"Price_overall\", \"Price_avg\", \"Review\", \"Review 10/10\",\n",
    "            \"Completion\", \"Minutes Listened\", \"Support Requests\", \"Last visited minus Purchase date\"]\n",
    "\n",
    "inputData = df_balanceado[features].values #no usamos la columna ID ya que no aporta nada\n",
    "# inputData = df_balanceado[:,1:-1] #forma equivalente\n",
    "\n",
    "targets = df_balanceado[\"Targets\"].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarizando datos\n",
    "\n",
    "Como hemos mencionado, es importante dentro del preprocesamiento hacer que los datos estén estandarizados, es decir, lograr que sus valores máximos y mínimos estén en un rango acotado y al mismo tiempo lograr que tengan media cero y desvío estándar 1 (o cercano a estos valores). Usaremos el método [standardscaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn-preprocessing-standardscaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book length (mins)_overall</th>\n",
       "      <th>Book length (mins)_avg</th>\n",
       "      <th>Price_overall</th>\n",
       "      <th>Price_avg</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review 10/10</th>\n",
       "      <th>Completion</th>\n",
       "      <th>Minutes Listened</th>\n",
       "      <th>Support Requests</th>\n",
       "      <th>Last visited minus Purchase date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4474.00</td>\n",
       "      <td>4474.00</td>\n",
       "      <td>4474.00</td>\n",
       "      <td>4474.00</td>\n",
       "      <td>4474.00</td>\n",
       "      <td>4474.00</td>\n",
       "      <td>4474.00</td>\n",
       "      <td>4474.00</td>\n",
       "      <td>4474.00</td>\n",
       "      <td>4474.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.69</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-11.83</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.21</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.21</td>\n",
       "      <td>5.94</td>\n",
       "      <td>18.16</td>\n",
       "      <td>14.92</td>\n",
       "      <td>2.27</td>\n",
       "      <td>1.61</td>\n",
       "      <td>4.64</td>\n",
       "      <td>7.81</td>\n",
       "      <td>19.42</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Book length (mins)_overall  Book length (mins)_avg  Price_overall  \\\n",
       "count                     4474.00                 4474.00        4474.00   \n",
       "mean                        -0.00                   -0.00          -0.00   \n",
       "std                          1.00                    1.00           1.00   \n",
       "min                         -2.69                   -1.85          -0.63   \n",
       "25%                         -0.74                   -0.74          -0.35   \n",
       "50%                          0.13                   -0.24          -0.23   \n",
       "75%                          1.21                    0.37           0.15   \n",
       "max                          1.21                    5.94          18.16   \n",
       "\n",
       "       Price_avg   Review  Review 10/10  Completion  Minutes Listened  \\\n",
       "count    4474.00  4474.00       4474.00     4474.00           4474.00   \n",
       "mean       -0.00    -0.00         -0.00       -0.00              0.00   \n",
       "std         1.00     1.00          1.00        1.00              1.00   \n",
       "min        -0.69    -0.44        -11.83       -0.39             -0.45   \n",
       "25%        -0.47    -0.44         -0.01       -0.39             -0.45   \n",
       "50%        -0.27    -0.44         -0.01       -0.39             -0.45   \n",
       "75%         0.04    -0.44         -0.01       -0.39             -0.19   \n",
       "max        14.92     2.27          1.61        4.64              7.81   \n",
       "\n",
       "       Support Requests  Last visited minus Purchase date  \n",
       "count           4474.00                           4474.00  \n",
       "mean              -0.00                              0.00  \n",
       "std                1.00                              1.00  \n",
       "min               -0.20                             -0.77  \n",
       "25%               -0.20                             -0.77  \n",
       "50%               -0.20                             -0.55  \n",
       "75%               -0.20                              0.65  \n",
       "max               19.42                              3.43  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "inputData_std = scaler.fit_transform(inputData)\n",
    "inputData_std = pd.DataFrame(inputData_std, columns = [\"Book length (mins)_overall\",\"Book length (mins)_avg\",\n",
    "                                                        \"Price_overall\", \"Price_avg\", \"Review\", \"Review 10/10\",\n",
    "                                                        \"Completion\", \"Minutes Listened\", \"Support Requests\",\n",
    "                                                        \"Last visited minus Purchase date\"])\n",
    "inputData_std.describe().round(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando datos en set de entrenamiento, validación y testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tarin = 0.8\n",
    "validation = 0.1\n",
    "test = 0.1\n",
    "\n",
    "#Primero separo en set de entrenamiento y de testeo\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(inputData_std.values, targets, test_size = 1 - tarin)\n",
    "\n",
    "#Ahora separo el set de testeo en sets de validación y de testeo\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size = test/(test + validation)) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardando los sets y el escalor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomentar las lineas debajo para guardar los sets\n",
    "\n",
    "# np.savez('datos_entrenamiento', inputs = x_train, target = y_train)\n",
    "# np.savez('datos_validación', inputs = x_val, targets = y_val)\n",
    "# np.savez('datos_testeo', inputs = x_test, targets = y_test)\n",
    "\n",
    "# pickle.dump(scaler, open(\"scaler.pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "costumeranalytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a04268169029a6c8c242914fc5adae46e7d2251e916247388ae8472995069ae4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
